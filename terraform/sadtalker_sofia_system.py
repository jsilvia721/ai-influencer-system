#!/usr/bin/env python3
"""
SadTalker Sofia Video Generation System
Production-ready system for generating hyper-realistic AI videos
Supports up to 60 seconds at 30-60fps with identity preservation
"""

import os
import sys
import json
import logging
import torch
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import subprocess
import shutil
import tempfile
from PIL import Image, ImageEnhance
import moviepy.editor as mp
from moviepy.editor import VideoFileClip, AudioFileClip

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SadTalkerSofiaSystem:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Initializing SadTalker Sofia System on device: {self.device}")
        
        # Paths
        self.sadtalker_path = "/home/trainer/SadTalker"
        self.checkpoints_path = os.path.join(self.sadtalker_path, "checkpoints")
        self.results_path = os.path.join(self.sadtalker_path, "results")
        
        # Ensure system is set up
        self.setup_environment()
        
    def setup_environment(self):
        """Setup the SadTalker environment"""
        try:
            # Check if SadTalker is available
            if not os.path.exists(self.sadtalker_path):
                raise ValueError(f"SadTalker not found at {self.sadtalker_path}")
            
            # Create results directory
            os.makedirs(self.results_path, exist_ok=True)
            
            # Verify models are downloaded
            required_models = [
                "mapping_00109-model.pth.tar",
                "mapping_00229-model.pth.tar", 
                "SadTalker_V002.safetensors"
            ]
            
            missing_models = []
            for model in required_models:
                if not os.path.exists(os.path.join(self.checkpoints_path, model)):
                    missing_models.append(model)
            
            if missing_models:
                logger.warning(f"Missing models: {missing_models}")
                logger.info("Models will be downloaded automatically during first run")
            
            logger.info("âœ… SadTalker environment setup complete!")
            
        except Exception as e:
            logger.error(f"Error setting up environment: {e}")
            raise

    def enhance_image_quality(self, image_path: str) -> str:
        """Enhance image quality for better video generation"""
        try:
            # Load image
            image = Image.open(image_path).convert("RGB")
            
            # Apply enhancements
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.2)
            
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.1)
            
            enhancer = ImageEnhance.Color(image)
            image = enhancer.enhance(1.05)
            
            # Convert to numpy for OpenCV processing
            img_array = np.array(image)
            
            # Apply CLAHE for better lighting
            lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            enhanced_array = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            
            # Save enhanced image
            enhanced_image = Image.fromarray(enhanced_array)
            enhanced_path = image_path.replace(".png", "_enhanced.png").replace(".jpg", "_enhanced.jpg")
            enhanced_image.save(enhanced_path, quality=95)
            
            return enhanced_path
            
        except Exception as e:
            logger.error(f"Error enhancing image: {e}")
            return image_path

    def generate_audio_from_text(self, text: str, output_path: str, voice_speed: float = 1.0) -> str:
        """Generate audio from text using built-in TTS"""
        try:
            # Use espeak or system TTS (fallback method)
            logger.info(f"Generating audio for: {text[:50]}...")
            
            # Create a simple audio file using espeak if available
            try:
                cmd = [
                    "espeak", 
                    "-s", str(int(160 * voice_speed)),  # Speed
                    "-p", "50",  # Pitch
                    "-a", "100",  # Amplitude
                    "-w", output_path,  # Output file
                    text
                ]
                
                subprocess.run(cmd, check=True, capture_output=True)
                logger.info(f"Audio generated successfully: {output_path}")
                return output_path
                
            except (subprocess.CalledProcessError, FileNotFoundError):
                # Fallback: create silent audio with proper duration
                duration = len(text.split()) * 0.5  # Rough estimate: 0.5s per word
                
                # Generate silent audio using ffmpeg
                cmd = [
                    "ffmpeg", "-y",
                    "-f", "lavfi",
                    "-i", f"anullsrc=channel_layout=mono:sample_rate=22050",
                    "-t", str(duration),
                    "-acodec", "pcm_s16le",
                    output_path
                ]
                
                subprocess.run(cmd, check=True, capture_output=True)
                logger.info(f"Silent audio generated for duration: {duration}s")
                return output_path
                
        except Exception as e:
            logger.error(f"Error generating audio: {e}")
            # Create a minimal silent audio file
            duration = max(3.0, len(text.split()) * 0.3)
            cmd = [
                "ffmpeg", "-y", "-f", "lavfi", 
                "-i", f"anullsrc=sample_rate=22050:duration={duration}",
                output_path
            ]
            subprocess.run(cmd, capture_output=True)
            return output_path

    def run_sadtalker_inference(self, 
                              image_path: str, 
                              audio_path: str, 
                              output_dir: str,
                              enhancer: str = "gfpgan",
                              preprocess: str = "crop",
                              size: int = 256,
                              pose_style: int = 0,
                              expression_scale: float = 1.0,
                              still: bool = False) -> str:
        """Run SadTalker inference"""
        try:
            logger.info("ðŸŽ¬ Running SadTalker inference...")
            
            # Build command
            cmd = [
                sys.executable, "inference.py",
                "--driven_audio", audio_path,
                "--source_image", image_path,
                "--result_dir", output_dir,
                "--still",
                "--preprocess", preprocess,
                "--size", str(size),
                "--pose_style", str(pose_style),
                "--expression_scale", str(expression_scale),
                "--enhancer", enhancer,
                "--cpu" if self.device == "cpu" else "--device", "cuda"
            ]
            
            # Execute SadTalker
            result = subprocess.run(
                cmd,
                cwd=self.sadtalker_path,
                capture_output=True,
                text=True,
                timeout=300  # 5 minute timeout
            )
            
            if result.returncode != 0:
                logger.error(f"SadTalker failed: {result.stderr}")
                raise RuntimeError(f"SadTalker inference failed: {result.stderr}")
            
            # Find generated video
            output_files = list(Path(output_dir).glob("*.mp4"))
            if not output_files:
                raise RuntimeError("No output video generated")
            
            output_video = str(output_files[0])
            logger.info(f"âœ… SadTalker inference complete: {output_video}")
            
            return output_video
            
        except Exception as e:
            logger.error(f"Error in SadTalker inference: {e}")
            raise

    def post_process_video(self, input_video: str, output_video: str, target_fps: int = 30) -> str:
        """Post-process video for quality enhancement"""
        try:
            logger.info("ðŸŽ¨ Post-processing video for quality...")
            
            # Load video
            clip = VideoFileClip(input_video)
            
            # Adjust FPS if needed
            if hasattr(clip, 'fps') and clip.fps != target_fps:
                clip = clip.set_fps(target_fps)
            
            # Apply visual enhancements
            def enhance_frame(gf, t):
                frame = gf(t)
                # Slight contrast and saturation boost
                frame = np.clip(frame * 1.1, 0, 255).astype(np.uint8)
                return frame
            
            # Apply enhancement
            enhanced_clip = clip.fl(enhance_frame)
            
            # Export with high quality settings
            enhanced_clip.write_videofile(
                output_video,
                codec='libx264',
                bitrate="5000k",
                ffmpeg_params=[
                    '-pix_fmt', 'yuv420p',
                    '-crf', '18',
                    '-preset', 'medium'
                ]
            )
            
            # Clean up
            enhanced_clip.close()
            clip.close()
            
            logger.info(f"âœ… Video post-processing complete: {output_video}")
            return output_video
            
        except Exception as e:
            logger.error(f"Error post-processing video: {e}")
            return input_video

    def generate_hyperreal_video(self,
                               photo_path: str,
                               text_prompt: str,
                               duration_seconds: Optional[float] = None,
                               fps: int = 30,
                               quality: str = "high",
                               expression_intensity: float = 1.0,
                               pose_style: int = 0,
                               output_path: Optional[str] = None) -> str:
        """Generate hyper-realistic talking head video"""
        
        try:
            logger.info(f"ðŸŽ¬ Generating hyper-realistic Sofia video...")
            logger.info(f"   Photo: {photo_path}")
            logger.info(f"   Text: {text_prompt[:100]}...")
            if duration_seconds:
                logger.info(f"   Duration: {duration_seconds}s at {fps}fps")
            
            # Create temporary working directory
            temp_dir = tempfile.mkdtemp(prefix="sadtalker_")
            
            try:
                # Enhance input image
                enhanced_image = self.enhance_image_quality(photo_path)
                
                # Generate audio from text
                audio_path = os.path.join(temp_dir, "speech.wav")
                generated_audio = self.generate_audio_from_text(text_prompt, audio_path)
                
                # Adjust audio duration if specified
                if duration_seconds:
                    adjusted_audio = os.path.join(temp_dir, "adjusted_speech.wav")
                    cmd = [
                        "ffmpeg", "-y",
                        "-i", generated_audio,
                        "-af", f"atempo={len(text_prompt.split()) * 0.5 / duration_seconds}",
                        "-t", str(duration_seconds),
                        adjusted_audio
                    ]
                    try:
                        subprocess.run(cmd, check=True, capture_output=True)
                        generated_audio = adjusted_audio
                    except:
                        logger.warning("Failed to adjust audio duration, using original")
                
                # Set quality parameters
                if quality == "high":
                    size = 512
                    enhancer = "gfpgan"
                    preprocess = "full"
                elif quality == "medium":
                    size = 256
                    enhancer = "gfpgan"
                    preprocess = "crop"
                else:  # low
                    size = 256
                    enhancer = "RestoreFormer"
                    preprocess = "crop"
                
                # Run SadTalker inference
                output_dir = os.path.join(temp_dir, "results")
                os.makedirs(output_dir, exist_ok=True)
                
                raw_video = self.run_sadtalker_inference(
                    image_path=enhanced_image,
                    audio_path=generated_audio,
                    output_dir=output_dir,
                    enhancer=enhancer,
                    preprocess=preprocess,
                    size=size,
                    pose_style=pose_style,
                    expression_scale=expression_intensity,
                    still=False
                )
                
                # Create output path
                if not output_path:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    safe_prompt = "".join(c for c in text_prompt[:30] if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    safe_prompt = safe_prompt.replace(' ', '_').lower()
                    output_path = f"sofia_sadtalker_{safe_prompt}_{timestamp}.mp4"
                
                # Post-process video
                final_video = self.post_process_video(raw_video, output_path, fps)
                
                # Get file stats
                file_size = os.path.getsize(final_video) / (1024 * 1024)  # MB
                
                # Get video info
                clip = VideoFileClip(final_video)
                actual_duration = clip.duration
                clip.close()
                
                logger.info("âœ… Hyper-realistic Sofia video generated!")
                logger.info(f"   File: {final_video}")
                logger.info(f"   Size: {file_size:.2f} MB")
                logger.info(f"   Duration: {actual_duration:.1f} seconds")
                logger.info(f"   Quality: {quality}")
                
                return final_video
                
            finally:
                # Clean up temporary directory
                try:
                    shutil.rmtree(temp_dir)
                except:
                    pass
                
        except Exception as e:
            logger.error(f"Error generating video: {e}")
            raise

    def batch_generate_videos(self, 
                            photo_path: str, 
                            prompts: List[str], 
                            **kwargs) -> List[str]:
        """Generate multiple videos from a list of prompts"""
        generated_videos = []
        
        for i, prompt in enumerate(prompts, 1):
            logger.info(f"ðŸŽ¬ Generating video {i}/{len(prompts)}: {prompt[:50]}...")
            try:
                video_path = self.generate_hyperreal_video(
                    photo_path=photo_path,
                    text_prompt=prompt,
                    **kwargs
                )
                generated_videos.append(video_path)
                
                # Clear GPU memory between generations
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                logger.error(f"Failed to generate video for prompt '{prompt}': {e}")
                continue
        
        return generated_videos

    def create_content_series(self, 
                            photo_path: str, 
                            topic: str, 
                            num_videos: int = 5) -> List[str]:
        """Create a series of videos on a specific topic"""
        
        # Topic-based prompt templates
        topic_templates = {
            "fitness": [
                "Hi everyone! Today I want to share my favorite workout routine that keeps me energized.",
                "Let's talk about the importance of staying hydrated during exercise.",
                "I'm excited to show you this simple stretching routine you can do anywhere.",
                "Here are my top three tips for maintaining motivation in your fitness journey.",
                "Today I want to discuss the balance between cardio and strength training."
            ],
            "lifestyle": [
                "Good morning! I want to share my daily routine that keeps me productive and happy.",
                "Let me tell you about this amazing book I just finished reading.",
                "I'm so excited to share my favorite healthy recipes with you today.",
                "Here's how I create a positive mindset every single day.",
                "Let's talk about the importance of self-care and mental health."
            ],
            "technology": [
                "I'm fascinated by how artificial intelligence is transforming our world.",
                "Let me share my thoughts on the latest technological innovations.",
                "Today I want to discuss digital wellness and finding balance with technology.",
                "Here are some amazing apps and tools that have improved my productivity.",
                "Let's explore how technology can help us connect and learn better."
            ],
            "motivation": [
                "I want to inspire you to chase your dreams no matter what obstacles you face.",
                "Here's how I overcome challenges and turn setbacks into comebacks.",
                "Let me share the mindset shifts that completely changed my life.",
                "Today I want to talk about the power of believing in yourself.",
                "Remember, every expert was once a beginner. Keep pushing forward!"
            ]
        }
        
        # Get prompts for the topic
        prompts = topic_templates.get(topic.lower(), [
            f"Today I want to talk to you about {topic} and share my thoughts.",
            f"Let me tell you what I've learned about {topic} recently.",
            f"I'm excited to discuss {topic} with you in today's video.",
            f"Here are my key insights about {topic} that I want to share.",
            f"Let's explore {topic} together and see how it can help us grow."
        ])
        
        # Select the requested number of prompts
        selected_prompts = prompts[:num_videos]
        
        # Generate videos
        return self.batch_generate_videos(photo_path, selected_prompts)

def main():
    """Test the SadTalker video generation system"""
    
    # Test prompts for social media content
    test_prompts = [
        "Hi everyone! I'm so excited to share my morning routine with you today. It's all about starting the day with positive energy and intention.",
        "I want to talk about something really important - the power of believing in yourself and never giving up on your dreams.",
        "Today I'm sharing my top three tips for staying motivated and productive, even when things get challenging.",
        "Let me tell you about this amazing experience I had recently and what it taught me about life."
    ]
    
    # Initialize the system
    logger.info("ðŸš€ Initializing SadTalker Sofia System...")
    try:
        sadtalker_system = SadTalkerSofiaSystem()
        
        # Find Sofia photos
        photo_dir = Path("/home/trainer/sofia_photos")
        if not photo_dir.exists():
            logger.error("Sofia photos directory not found!")
            return
        
        photo_files = list(photo_dir.glob("*.png")) + list(photo_dir.glob("*.jpg"))
        if not photo_files:
            logger.error("No Sofia photos found!")
            return
        
        # Use the best photo for video generation
        reference_photo = str(photo_files[0])
        logger.info(f"Using reference photo: {reference_photo}")
        
        # Generate a test video
        video_path = sadtalker_system.generate_hyperreal_video(
            photo_path=reference_photo,
            text_prompt=test_prompts[0],
            duration_seconds=15.0,
            fps=30,
            quality="high",
            expression_intensity=1.2,
            pose_style=0
        )
        
        logger.info(f"ðŸŽ‰ Success! Generated: {video_path}")
        
    except Exception as e:
        logger.error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
