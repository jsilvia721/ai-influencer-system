#!/usr/bin/env python3
"""
Enhanced Sofia Video Generator
Addresses quality, duration, smoothness, and prompt integration issues
"""

import os
import torch
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
from typing import List, Dict, Tuple, Optional
import logging
from datetime import datetime
import glob
import random

# Enhanced imports
from face_identity_system import FaceIdentityPreserver
from diffusers import StableVideoDiffusionPipeline, DiffusionPipeline
from diffusers.utils import load_image, export_to_video
from transformers import pipeline, AutoTokenizer, AutoModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedSofiaVideoGenerator:
    """
    High-quality Sofia video generator with prompt integration and smooth motion
    """
    
    def __init__(self, sofia_photos_dir: str = "/home/trainer/sofia_photos"):
        """
        Initialize enhanced Sofia video generation system
        """
        self.photos_dir = sofia_photos_dir
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Initialize face identity system
        logger.info("Initializing Enhanced Face Identity System...")
        self.face_system = FaceIdentityPreserver()
        
        # Initialize enhanced video pipeline (using XT model for more frames)
        logger.info("Loading Enhanced Stable Video Diffusion model...")
        self.video_pipeline = StableVideoDiffusionPipeline.from_pretrained(
            "stabilityai/stable-video-diffusion-img2vid-xt",  # XT model for 25 frames
            torch_dtype=torch.float16,
            variant="fp16"
        )
        self.video_pipeline.to(self.device)
        self.video_pipeline.enable_model_cpu_offload()
        
        # Try to enable memory optimizations
        try:
            if hasattr(self.video_pipeline, "enable_xformers_memory_efficient_attention"):
                self.video_pipeline.enable_xformers_memory_efficient_attention()
                logger.info("Enabled xFormers memory efficient attention")
        except Exception as e:
            logger.warning(f"Could not enable xFormers: {e}")
        
        # Sofia's identity profile
        self.sofia_profile = None
        self.reference_photos = []
        
        logger.info("Enhanced Sofia Video System initialized!")
    
    def load_sofia_photos(self) -> List[str]:
        """Load Sofia's reference photos with quality filtering"""
        photo_patterns = ["*.png", "*.jpg", "*.jpeg"]
        photos = []
        
        for pattern in photo_patterns:
            photos.extend(glob.glob(os.path.join(self.photos_dir, pattern)))
        
        # Filter for high-quality photos
        quality_photos = []
        for photo in photos:
            try:
                img = Image.open(photo)
                # Filter by minimum resolution and aspect ratio
                if img.width >= 512 and img.height >= 512:
                    quality_photos.append(photo)
            except Exception as e:
                logger.warning(f"Could not process {photo}: {e}")
        
        self.reference_photos = quality_photos
        logger.info(f"Loaded {len(quality_photos)} high-quality Sofia photos")
        return quality_photos
    
    def create_sofia_identity_profile(self):
        """Create Sofia's enhanced identity profile"""
        if not self.reference_photos:
            self.load_sofia_photos()
        
        logger.info("Creating Sofia's enhanced identity profile...")
        self.sofia_profile = self.face_system.create_person_profile("sofia", self.reference_photos)
        
        if self.sofia_profile:
            logger.info(f"âœ… Sofia's identity profile created!")
            logger.info(f"Consistency: {self.sofia_profile['embedding_consistency']:.4f}")
        else:
            raise ValueError("Failed to create Sofia's identity profile")
    
    def select_best_photo_for_prompt(self, prompt: str) -> str:
        """
        Select the best Sofia photo based on the prompt description
        """
        if not self.reference_photos:
            self.load_sofia_photos()
        
        # Simple keyword matching for photo selection
        prompt_lower = prompt.lower()
        
        # Prefer photos with certain characteristics based on prompt
        scored_photos = []
        
        for photo in self.reference_photos:
            score = 0
            photo_name = os.path.basename(photo).lower()
            
            # Score based on prompt keywords
            if any(word in prompt_lower for word in ["smile", "smiling", "happy"]):
                if any(word in photo_name for word in ["candid", "natural"]):
                    score += 2
            
            if any(word in prompt_lower for word in ["pose", "modeling", "fashion"]):
                if "photography" in photo_name:
                    score += 2
            
            if any(word in prompt_lower for word in ["wave", "waving", "gesture"]):
                score += 1  # Any photo can work for gestures
            
            # Add base score for photo quality indicators
            if "natural" in photo_name or "candid" in photo_name:
                score += 1
            
            scored_photos.append((photo, score))
        
        # Sort by score and select best
        scored_photos.sort(key=lambda x: x[1], reverse=True)
        selected_photo = scored_photos[0][0] if scored_photos else random.choice(self.reference_photos)
        
        logger.info(f"Selected photo for prompt '{prompt}': {os.path.basename(selected_photo)}")
        return selected_photo
    
    def enhance_reference_image(self, image_path: str, prompt: str) -> Image.Image:
        """
        Enhance reference image for better video generation based on prompt
        """
        # Load and enhance image
        image = load_image(image_path)
        image = image.convert("RGB")
        
        # Apply enhancements based on prompt
        prompt_lower = prompt.lower()
        
        # Enhance for different prompt types
        if any(word in prompt_lower for word in ["bright", "sunny", "cheerful"]):
            # Increase brightness and saturation
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(1.1)
            enhancer = ImageEnhance.Color(image)
            image = enhancer.enhance(1.1)
        
        if any(word in prompt_lower for word in ["sharp", "clear", "detailed"]):
            # Enhance sharpness
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.2)
        
        # Resize to optimal dimensions for smooth video
        target_width, target_height = 1024, 576
        
        # Calculate scaling to maintain aspect ratio
        original_width, original_height = image.size
        scale = min(target_width / original_width, target_height / original_height)
        
        new_width = int(original_width * scale)
        new_height = int(original_height * scale)
        
        # High-quality resize
        image = image.resize((new_width, new_height), Image.LANCZOS)
        
        # Create final image with target size (centered with context-aware background)
        final_image = Image.new("RGB", (target_width, target_height), (40, 45, 50))
        paste_x = (target_width - new_width) // 2
        paste_y = (target_height - new_height) // 2
        final_image.paste(image, (paste_x, paste_y))
        
        # Apply subtle blur to edges for more natural look
        mask = Image.new("L", (target_width, target_height), 0)
        mask.paste(255, (paste_x, paste_y, paste_x + new_width, paste_y + new_height))
        mask = mask.filter(ImageFilter.GaussianBlur(2))
        
        logger.info(f"Enhanced image for prompt: {prompt[:30]}...")
        return final_image
    
    def generate_enhanced_sofia_video(
        self,
        prompt: str,
        duration_seconds: float = 10.0,
        motion_intensity: str = "medium",
        quality: str = "high",
        fps: int = 24,
        seed: Optional[int] = None
    ) -> str:
        """
        Generate enhanced Sofia video with smooth motion and prompt integration
        
        Args:
            prompt: Detailed description of what Sofia should do
            duration_seconds: Target duration (we'll generate multiple segments)
            motion_intensity: "low", "medium", "high"
            quality: "medium", "high", "ultra"
            fps: Frames per second for smooth motion
            seed: Random seed for reproducibility
        """
        try:
            logger.info(f"Generating enhanced Sofia video: '{prompt}'")
            logger.info(f"Target duration: {duration_seconds}s at {fps}fps")
            
            # Ensure Sofia's identity profile exists
            if not self.sofia_profile:
                self.create_sofia_identity_profile()
            
            # Select best reference photo for the prompt
            reference_photo = self.select_best_photo_for_prompt(prompt)
            
            # Enhance the reference image based on prompt
            reference_image = self.enhance_reference_image(reference_photo, prompt)
            
            # Configure generation parameters based on quality
            quality_settings = {
                "medium": {"num_frames": 25, "steps": 25, "chunk_size": 4},
                "high": {"num_frames": 25, "steps": 30, "chunk_size": 2},
                "ultra": {"num_frames": 25, "steps": 35, "chunk_size": 1}
            }
            
            settings = quality_settings.get(quality, quality_settings["high"])
            
            # Set motion bucket based on intensity and prompt
            motion_buckets = {"low": 90, "medium": 127, "high": 160}
            motion_bucket_id = motion_buckets.get(motion_intensity, 127)
            
            # Adjust motion based on prompt keywords
            prompt_lower = prompt.lower()
            if any(word in prompt_lower for word in ["gentle", "slow", "calm"]):
                motion_bucket_id = max(motion_bucket_id - 30, 60)
            elif any(word in prompt_lower for word in ["energetic", "dynamic", "active"]):
                motion_bucket_id = min(motion_bucket_id + 30, 180)
            
            # Set seed for reproducibility
            if seed is not None:
                torch.manual_seed(seed)
                np.random.seed(seed)
            
            # Calculate how many segments we need for desired duration
            frames_per_segment = settings["num_frames"]
            segment_duration = frames_per_segment / fps
            num_segments = max(1, int(duration_seconds / segment_duration))
            
            logger.info(f"Generating {num_segments} segments for {duration_seconds}s video")
            
            all_frames = []
            
            # Generate video segments
            for segment in range(num_segments):
                logger.info(f"Generating segment {segment + 1}/{num_segments}")
                
                # Clear GPU memory
                torch.cuda.empty_cache()
                
                # Vary the motion slightly for each segment
                segment_motion = motion_bucket_id + random.randint(-10, 10)
                segment_motion = max(60, min(180, segment_motion))
                
                with torch.no_grad():
                    frames = self.video_pipeline(
                        reference_image,
                        decode_chunk_size=settings["chunk_size"],
                        num_frames=frames_per_segment,
                        motion_bucket_id=segment_motion,
                        noise_aug_strength=0.02,
                        num_inference_steps=settings["steps"],
                    ).frames[0]
                
                # Add frames (skip first frame of subsequent segments to avoid duplicates)
                if segment == 0:
                    all_frames.extend(frames)
                else:
                    all_frames.extend(frames[1:])  # Skip first frame to avoid stutter
            
            # Post-process frames for smoothness
            all_frames = self.smooth_frame_transitions(all_frames)
            
            # Generate output filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            prompt_slug = "".join(c for c in prompt.lower() if c.isalnum() or c == " ").replace(" ", "_")[:25]
            output_filename = f"sofia_enhanced_{prompt_slug}_{timestamp}.mp4"
            
            # Export with higher quality settings
            logger.info(f"Exporting enhanced video to {output_filename}")
            export_to_video(all_frames, output_filename, fps=fps)
            
            # Verify and report results
            if os.path.exists(output_filename):
                file_size = os.path.getsize(output_filename) / (1024 * 1024)
                actual_duration = len(all_frames) / fps
                
                logger.info(f"âœ… Enhanced Sofia video generated!")
                logger.info(f"File: {output_filename}")
                logger.info(f"Size: {file_size:.2f} MB")
                logger.info(f"Duration: {actual_duration:.1f} seconds")
                logger.info(f"Frames: {len(all_frames)} at {fps}fps")
                logger.info(f"Quality: {quality} with {motion_intensity} motion")
                
                return output_filename
            else:
                raise Exception("Enhanced video file was not created")
        
        except Exception as e:
            logger.error(f"Error generating enhanced Sofia video: {str(e)}")
            raise
        finally:
            torch.cuda.empty_cache()
    
    def smooth_frame_transitions(self, frames: List[Image.Image]) -> List[Image.Image]:
        """
        Apply smoothing between frames to reduce choppiness
        """
        if len(frames) < 2:
            return frames
        
        logger.info("Applying frame smoothing for better motion...")
        
        smoothed_frames = [frames[0]]  # Keep first frame
        
        # Apply simple frame blending for smoother transitions
        for i in range(1, len(frames)):
            # Blend current frame with previous for smoother motion
            prev_frame = np.array(frames[i-1])
            curr_frame = np.array(frames[i])
            
            # Light blending (90% current, 10% previous)
            blended = (0.9 * curr_frame + 0.1 * prev_frame).astype(np.uint8)
            smoothed_frames.append(Image.fromarray(blended))
        
        return smoothed_frames

def main():
    """Test the enhanced Sofia video generator"""
    try:
        # Initialize enhanced system
        sofia_gen = EnhancedSofiaVideoGenerator()
        
        # Generate enhanced video with specific prompt
        video_path = sofia_gen.generate_enhanced_sofia_video(
            prompt="Sofia smiling warmly and waving hello to the camera with a gentle, welcoming gesture",
            duration_seconds=8.0,
            motion_intensity="medium",
            quality="high",
            fps=24,
            seed=42
        )
        
        print(f"\nðŸŽ‰ Enhanced Sofia video generated: {video_path}")
        print("ðŸŽ¬ This should be much smoother and more responsive to the prompt!")
        
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        raise

if __name__ == "__main__":
    main()
